{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 keras models\n",
    "### Following the mnist tutorial linked from previous notebook\n",
    "Build and train a model to predict handwritten digits from mnist dataset.  \n",
    "The typical Keras workflow looks just like this:\n",
    "1. Define your training data: input tensors and target tensors.\n",
    "2. Define a network of layers (or model ) that maps your inputs to your targets.\n",
    "3. Configure the learning process by choosing a loss function, an optimizer, and some metrics to monitor.\n",
    "4. Iterate on your training data by calling the fit() method of your model.\n",
    "\n",
    "Great video [here](https://www.youtube.com/watch?v=5qCDzaOUCWA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/Users/christiancleve/Library/Python/3.9/lib/python/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/Users/christiancleve/Library/Python/3.9/lib/python/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/Users/christiancleve/Library/Python/3.9/lib/python/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: dlopen(/Users/christiancleve/Library/Python/3.9/lib/python/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 0x0006): tried: '/Users/christiancleve/Library/Python/3.9/lib/python/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Users/christiancleve/Library/Python/3.9/lib/python/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/christiancleve/Library/Python/3.9/lib/python/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64'))\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/pywrap_tensorflow.py:58\u001B[0m\n\u001B[1;32m     56\u001B[0m   sys\u001B[38;5;241m.\u001B[39msetdlopenflags(_default_dlopen_flags \u001B[38;5;241m|\u001B[39m ctypes\u001B[38;5;241m.\u001B[39mRTLD_LOCAL)\n\u001B[0;32m---> 58\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpywrap_tensorflow_internal\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpywrap_tensorflow_internal\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __version__\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/pywrap_tensorflow_internal.py:28\u001B[0m\n\u001B[1;32m     27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _mod\n\u001B[0;32m---> 28\u001B[0m _pywrap_tensorflow_internal \u001B[38;5;241m=\u001B[39m \u001B[43mswig_import_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m swig_import_helper\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/pywrap_tensorflow_internal.py:24\u001B[0m, in \u001B[0;36mswig_import_helper\u001B[0;34m()\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 24\u001B[0m     _mod \u001B[38;5;241m=\u001B[39m \u001B[43mimp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m_pywrap_tensorflow_internal\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpathname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/imp.py:242\u001B[0m, in \u001B[0;36mload_module\u001B[0;34m(name, file, filename, details)\u001B[0m\n\u001B[1;32m    241\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 242\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mload_dynamic\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m type_ \u001B[38;5;241m==\u001B[39m PKG_DIRECTORY:\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/imp.py:342\u001B[0m, in \u001B[0;36mload_dynamic\u001B[0;34m(name, path, file)\u001B[0m\n\u001B[1;32m    340\u001B[0m spec \u001B[38;5;241m=\u001B[39m importlib\u001B[38;5;241m.\u001B[39mmachinery\u001B[38;5;241m.\u001B[39mModuleSpec(\n\u001B[1;32m    341\u001B[0m     name\u001B[38;5;241m=\u001B[39mname, loader\u001B[38;5;241m=\u001B[39mloader, origin\u001B[38;5;241m=\u001B[39mpath)\n\u001B[0;32m--> 342\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mspec\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mImportError\u001B[0m: dlopen(/Users/christiancleve/Library/Python/3.9/lib/python/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 0x0006): tried: '/Users/christiancleve/Library/Python/3.9/lib/python/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Users/christiancleve/Library/Python/3.9/lib/python/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/christiancleve/Library/Python/3.9/lib/python/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [26], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mnist\n\u001B[1;32m      3\u001B[0m (x_train, y_train), (x_test, y_test) \u001B[38;5;241m=\u001B[39m mnist\u001B[38;5;241m.\u001B[39mload_data()\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/keras/__init__.py:21\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \n\u001B[1;32m     17\u001B[0m \u001B[38;5;124;03mDetailed documentation and user guides are available at\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;124;03m[keras.io](https://keras.io).\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distribute\n\u001B[0;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m models\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minput_layer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Input\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msequential\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/keras/models/__init__.py:18\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# ==============================================================================\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Functional\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msequential\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtraining\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Model\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/keras/engine/functional.py:24\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mitertools\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[0;32m---> 24\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtensor\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m layout_map \u001B[38;5;28;01mas\u001B[39;00m layout_map_lib\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/__init__.py:24\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_os\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# pylint: disable=g-bad-import-order\u001B[39;00m\n\u001B[0;32m---> 24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pywrap_tensorflow  \u001B[38;5;66;03m# pylint: disable=unused-import\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     27\u001B[0m   \u001B[38;5;66;03m# Add `estimator` attribute to allow access to estimator APIs via\u001B[39;00m\n\u001B[1;32m     28\u001B[0m   \u001B[38;5;66;03m# \"tf.estimator...\"\u001B[39;00m\n\u001B[1;32m     29\u001B[0m   \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mestimator\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m estimator  \u001B[38;5;66;03m# pylint: disable=g-import-not-at-top\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/__init__.py:49\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m# TODO(drpng): write up instructions for editing this file in a doc and point to\u001B[39;00m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# the doc instead.\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# If you want to edit this file to expose modules in public tensorflow API, you\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;66;03m# go/tf-wildcard-import\u001B[39;00m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001B[39;00m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m---> 49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pywrap_tensorflow\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m component_api_helper\n\u001B[1;32m     52\u001B[0m component_api_helper\u001B[38;5;241m.\u001B[39mpackage_hook(\n\u001B[1;32m     53\u001B[0m     parent_package_str\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtensorflow.python\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     54\u001B[0m     child_package_str\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m     55\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtensorflow_estimator.python.estimator\u001B[39m\u001B[38;5;124m'\u001B[39m))\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/pywrap_tensorflow.py:74\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[1;32m     70\u001B[0m   msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mFailed to load the native TensorFlow runtime.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;124mSee https://www.tensorflow.org/install/errors\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;124mfor some common reasons and solutions.  Include the entire stack trace\u001B[39m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;124mabove this error message when asking for help.\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m \u001B[38;5;241m%\u001B[39m traceback\u001B[38;5;241m.\u001B[39mformat_exc()\n\u001B[0;32m---> 74\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(msg)\n",
      "\u001B[0;31mImportError\u001B[0m: Traceback (most recent call last):\n  File \"/Users/christiancleve/Library/Python/3.9/lib/python/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/Users/christiancleve/Library/Python/3.9/lib/python/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/Users/christiancleve/Library/Python/3.9/lib/python/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: dlopen(/Users/christiancleve/Library/Python/3.9/lib/python/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 0x0006): tried: '/Users/christiancleve/Library/Python/3.9/lib/python/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Users/christiancleve/Library/Python/3.9/lib/python/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (no such file), '/Users/christiancleve/Library/Python/3.9/lib/python/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64'))\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [24], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# x_train[35]\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTarget on entity no. 35: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my_train[\u001B[38;5;241m35\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSome rows from input on entity no 35: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx_train[\u001B[38;5;241m35\u001B[39m][\u001B[38;5;241m10\u001B[39m:\u001B[38;5;241m15\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "# x_train[35]\n",
    "print(f'Target on entity no. 35: {y_train[35]}')\n",
    "print('\\n\\n\\n')\n",
    "print(f'Some rows from input on entity no 35: {x_train[35][10:15]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_index = 35\n",
    "print(y_train[image_index])\n",
    "plt.imshow(x_train[image_index], cmap='Greys')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape\n",
    "#28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data from 0-255 to 0-1\n",
    "(x_train_original, y_train_original), (x_test_original, y_test_original) = mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = (x_train_original, y_train_original), (x_test_original, y_test_original)\n",
    "image_size = 28*28\n",
    "x_train = x_train.reshape(x_train.shape[0],image_size) # x_train = (60000,784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0],image_size)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "\n",
    "x_train[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical # to get a one-hot incoding of the target data\n",
    "num_classes = 10\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "y_test[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out the to_categorical method\n",
    "print(to_categorical([0],10))\n",
    "print(to_categorical([1],10))\n",
    "print(to_categorical([2],10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing layers for the model\n",
    "From Deep learning with python p. 59:\n",
    "\n",
    "Different layers are appropriate for different tensor formats and different types of data processing. For instance: \n",
    "1. simple vector data, stored in 2D tensors of shape (samples, features), is often processed by densely connected layers, also called fully connected or dense layers (the Dense class in Keras). \n",
    "2. Sequence data, stored in 3D tensors of shape (samples, timesteps, features), is typically processed by recurrent layers such as an LSTM layer.\n",
    "3. Image data, stored in 4D tensors, is usually processed by 2D convolution layers (Conv2D).\n",
    "\n",
    "Think of layers as the LEGO bricks of deep learning, a metaphor that is made explicit by frameworks like Keras. Building deep-learning models in Keras is done by clipping together compatible layers to form useful data-transformation pipelines. The notion of layer compatibility here refers specifically to the fact that every layer\n",
    "will only accept input tensors of a certain shape and will return output tensors of a certain shape. Consider the following example from keras import layers: `layer = layers.Dense(32, input_shape=(784,))`  \n",
    "A dense layer with 32 output units\n",
    "We’re creating a layer that will only accept as input 2D tensors where the first dimen-\n",
    "sion is 784 (axis 0, the batch dimension, is unspecified, and thus any value would be\n",
    "accepted). This layer will return a tensor where the first dimension has been trans-\n",
    "formed to be 32.\n",
    "\n",
    "Thus this layer can only be connected to a downstream layer that expects 32-\n",
    "dimensional vectors as its input. When using Keras, you don’t have to worry about\n",
    "compatibility, because the layers you add to your models are dynamically built to\n",
    "match the shape of the incoming layer. For instance, suppose you write the following:\n",
    "from keras import models\n",
    "from keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, input_shape=(784,)))\n",
    "model.add(layers.Dense(32))\n",
    "The second layer didn’t receive an input shape argument—instead, it automatically\n",
    "inferred its input shape as being the output shape of the layer that came before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "# model instance\n",
    "model = Sequential()\n",
    "# define each layer in the network\n",
    "from keras.layers import Dense # the simplest layer type\n",
    "\n",
    "input_layer = Dense(units=512,  # 512 units (nodes) is an arbitrary number (might be ajusted later up or down to see what gives most accuracy)\n",
    "                activation='sigmoid', # activation is the activation function used to pass dot product of all inputs and weights through\n",
    "                input_shape=(image_size, )) #28x28 for the mnist image size (must be an iterable, therefore the comma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (image_size,):\n",
    "    print(i)\n",
    "print(len((image_size,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add hidden layer\n",
    "model.add(input_layer)\n",
    "# add another  hidden layer\n",
    "model.add(Dense(units=512,activation='sigmoid'))\n",
    "\n",
    "#model.add(Dense(units=48,activation='relu'))\n",
    "\n",
    "# add an output layer\n",
    "model.add(Dense(units=10, \n",
    "                activation='softmax', # softmax nonlinearity function for mapping the neural network activation to the categories\n",
    "                #input_shape=(image_size,) # does not seem to be warranted\n",
    "               ))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now train the model\n",
    "model.compile(loss='categorical_crossentropy', # loss is how to meassure how wrong the model is on its predictions\n",
    "             optimizer='sgd', # \"stochastic gradient descent\" is a way to tell algorithm how to improve\n",
    "             metrics=['accuracy'], # what do we care about in our model\n",
    "             )\n",
    "model.fit(x_train,\n",
    "         y_train,\n",
    "         epochs=5,\n",
    "         verbose=True,\n",
    "         validation_split=0.1) # checking periodically how well we are doing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "- **Loss functions:** Different ways to calculate the difference between target and network output\n",
    "- **Optimizers:** Multiple variants of Stocastic Gradient Descent (SGD) that differ by taking into account previous weight updates when computing the next weight update, rather than just looking at the current value of the gradients. There is, for instance, SGD with momentum, as well as Adagrad, RMSProp, and several others. Such variants are known as optimization methods or optimizers.\n",
    "- **metrics:** What we are looking for when we optimize and readjust our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_original[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (ax1, ax2, ax3) = plt.subplots(1,3)\n",
    "ax1.imshow(x_test_original[0], cmap='Greys')\n",
    "ax2.imshow(x_test_original[1], cmap='Greys')\n",
    "ax3.imshow(x_test_original[2], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "print(f'test loss, test acc:', results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print('\\n# Generate predictions for 3 samples')\n",
    "predictions = model.predict(x_test[:3])\n",
    "#print('predictions shape:', predictions.shape)\n",
    "#print(predictions)\n",
    "print('predict classes',model.predict_classes(x_test[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "num_classes = 10\n",
    "print(y_train.shape)\n",
    "print('y_train first value',y_train[0])\n",
    "# change the targets to one-hot-encoded\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "print(y_train.shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation here\n",
    "https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using convolutional neural network for image classification with keras\n",
    "https://www.machinecurve.com/index.php/2020/03/30/how-to-use-conv2d-with-keras/#what-are-convolutional-neural-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### more complex and more accurate model:\n",
    "\n",
    "\n",
    "# reformat input\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0],28,28,1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0],28,28,1)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "\n",
    "#reformat output\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "model2 = models.Sequential()\n",
    "# keras.layers.Conv2D(filters, kernel_size... filter is how many filters (windows of sub pixel set) kernel is the window size eg: 3x3 pixels\n",
    "model2.add(layers.Conv2D(32, (3,3), activation='relu',input_shape=(28,28,1)))\n",
    "model2.add(layers.MaxPool2D((2,2))) # Max Pooling to reduce the spatial dimensions of the output volume. pool_size: integer or tuple of 2 integers, factors by which to downscale (vertical, horizontal)\n",
    "model2.add(layers.Conv2D(64,(3,3),activation='relu')) # does not need input_shape, since it gets it from previous layer\n",
    "model2.add(layers.MaxPool2D((2,2)))\n",
    "model2.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model2.add(layers.Flatten()) # rewrite tensor to single vector of values\n",
    "model2.add(layers.Dense(64, activation='relu'))\n",
    "model2.add(layers.Dense(10, activation='softmax')) # softmax is good for output layer because Softmax outputs probabilities range. The range will 0 to 1, and the sum of all the probabilities will be equal to one. If the softmax function used for multi-classification model it returns the probabilities of each class and the target class will have the high probability.\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', # loss is how to meassure how wrong the model is on its predictions\n",
    "             optimizer='rmsprop', # \"stochastic gradient descent\" is a way to tell algorithm how to improve\n",
    "             metrics=['accuracy'], # what do we care about in our model\n",
    "             )\n",
    "model2.fit(x_train,\n",
    "         y_train,\n",
    "         epochs=5,\n",
    "         verbose=True,\n",
    "         batch_size=64,\n",
    "         validation_split=0.1) # checking periodically how well we are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model2.evaluate(x_test, y_test)\n",
    "print('test loss, test acc:', results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print('\\n# Generate predictions for 3 samples')\n",
    "predictions = model2.predict(x_test[:3])\n",
    "#print('predictions shape:', predictions.shape)\n",
    "print(predictions)\n",
    "print('predict classes',model2.predict_classes(x_test[:3]))\n",
    "print('actual:\\n',y_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
